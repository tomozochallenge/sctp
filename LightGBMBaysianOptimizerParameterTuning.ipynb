{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takuro17/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"resources/train.csv\")\n",
    "test_df = pd.read_csv(\"resources/test.csv\")\n",
    "submit_sample = pd.read_csv(\"resources/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:,2:].values\n",
    "y_train = train_df.iloc[:,1].values\n",
    "X_test = test_df.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "kmeans = KMeans(init='k-means++', n_clusters= 20, n_init=10)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "dist = DistanceMetric.get_metric('euclidean')\n",
    "ax_tr = dist.pairwise(X_train, kmeans.cluster_centers_)\n",
    "ax_te = dist.pairwise(X_test, kmeans.cluster_centers_)\n",
    "\n",
    "ax_tr = pd.DataFrame(ax_tr)\n",
    "ax_te = pd.DataFrame(ax_te)\n",
    "xcols =  ['dist' + str(f) for f in range(0, ax_tr.shape[1])]\n",
    "\n",
    "ax_tr.columns = xcols\n",
    "ax_te.columns = xcols\n",
    "\n",
    "m1 = X_train.max(axis = 1)\n",
    "m2 = X_train.min(axis = 1)\n",
    "m3 = train_df.median(axis = 1)\n",
    "m4 = 1/X_train.std(axis = 1)\n",
    "\n",
    "train_df['xmax'] = m1\n",
    "train_df['xmin'] = m2\n",
    "train_df['xmed'] = m3\n",
    "train_df['xstd'] = m4\n",
    "\n",
    "m1 = X_test.max(axis = 1)\n",
    "m2 = X_test.min(axis = 1)\n",
    "m3 = test_df.median(axis = 1)\n",
    "m4 = 1/X_test.std(axis = 1)\n",
    "\n",
    "test_df['xmax'] = m1\n",
    "test_df['xmin'] = m2\n",
    "test_df['xmed'] = m3\n",
    "test_df['xstd'] = m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_add = pd.concat([train_df, ax_tr], axis = 1)\n",
    "test_df_add = pd.concat([test_df, ax_te], axis = 1)\n",
    "\n",
    "X_train = train_df_add.iloc[:,2:].values\n",
    "y_train = train_df_add.iloc[:,1].values\n",
    "X_test = test_df_add.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  colSam   | maxDepth  | minChi... | numLeaves | scaleW... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "0.8822628486358797\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8823  \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 49.34   \u001b[0m | \u001b[0m 60.63   \u001b[0m | \u001b[0m 32.51   \u001b[0m | \u001b[0m 89.51   \u001b[0m | \u001b[0m 0.7266  \u001b[0m |\n",
      "0.8842407313596586\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8842  \u001b[0m | \u001b[95m 0.743   \u001b[0m | \u001b[95m 37.81   \u001b[0m | \u001b[95m 63.87   \u001b[0m | \u001b[95m 42.96   \u001b[0m | \u001b[95m 26.87   \u001b[0m | \u001b[95m 0.5667  \u001b[0m |\n",
      "0.8838531531384721\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8839  \u001b[0m | \u001b[0m 0.651   \u001b[0m | \u001b[0m 32.74   \u001b[0m | \u001b[0m 57.74   \u001b[0m | \u001b[0m 46.59   \u001b[0m | \u001b[0m 21.3    \u001b[0m | \u001b[0m 0.4893  \u001b[0m |\n",
      "0.8830322982740864\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.883   \u001b[0m | \u001b[0m 0.7965  \u001b[0m | \u001b[0m 31.02   \u001b[0m | \u001b[0m 54.88   \u001b[0m | \u001b[0m 39.99   \u001b[0m | \u001b[0m 30.77   \u001b[0m | \u001b[0m 0.7916  \u001b[0m |\n",
      "0.8685330586531862\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8685  \u001b[0m | \u001b[0m 0.7329  \u001b[0m | \u001b[0m 11.84   \u001b[0m | \u001b[0m 6.652   \u001b[0m | \u001b[0m 34.19   \u001b[0m | \u001b[0m 22.07   \u001b[0m | \u001b[0m 0.6377  \u001b[0m |\n",
      "0.8822342547192126\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8822  \u001b[0m | \u001b[0m 0.9238  \u001b[0m | \u001b[0m 2.368   \u001b[0m | \u001b[0m 69.58   \u001b[0m | \u001b[0m 41.53   \u001b[0m | \u001b[0m 98.4    \u001b[0m | \u001b[0m 0.6517  \u001b[0m |\n",
      "0.891804921480907\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.8918  \u001b[0m | \u001b[95m 0.7374  \u001b[0m | \u001b[95m 11.99   \u001b[0m | \u001b[95m 69.29   \u001b[0m | \u001b[95m 10.59   \u001b[0m | \u001b[95m 1.476   \u001b[0m | \u001b[95m 0.866   \u001b[0m |\n",
      "0.8895648568315762\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8896  \u001b[0m | \u001b[0m 0.9226  \u001b[0m | \u001b[0m 59.54   \u001b[0m | \u001b[0m 68.85   \u001b[0m | \u001b[0m 10.71   \u001b[0m | \u001b[0m 4.237   \u001b[0m | \u001b[0m 0.6473  \u001b[0m |\n",
      "0.8888383073767484\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8888  \u001b[0m | \u001b[0m 0.6531  \u001b[0m | \u001b[0m 10.39   \u001b[0m | \u001b[0m 69.87   \u001b[0m | \u001b[0m 11.96   \u001b[0m | \u001b[0m 5.823   \u001b[0m | \u001b[0m 0.8998  \u001b[0m |\n",
      "0.8900429305758755\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.89    \u001b[0m | \u001b[0m 0.5575  \u001b[0m | \u001b[0m 53.37   \u001b[0m | \u001b[0m 69.7    \u001b[0m | \u001b[0m 10.95   \u001b[0m | \u001b[0m 4.09    \u001b[0m | \u001b[0m 0.4159  \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18e9586cc4c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mbayesOpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-18e9586cc4c0>\u001b[0m in \u001b[0;36mbayesOpt\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mlgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mbayesOpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "#parameter tuning\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "def lgb_evaluate(numLeaves, maxDepth, scaleWeight, minChildWeight, subsample, colSam):   \n",
    "    clf = lgb.LGBMClassifier(\n",
    "        class_weight = 'balanced',\n",
    "        objective = 'binary',\n",
    "        metric= 'auc',\n",
    "        eval_metric= 'auc',\n",
    "        n_estimators=1000,\n",
    "        num_leaves= int(numLeaves),\n",
    "        max_depth= int(maxDepth),\n",
    "        scale_pos_weight= scaleWeight,\n",
    "        min_child_weight= minChildWeight,\n",
    "        subsample= subsample,\n",
    "        colsample_bytree= colSam,\n",
    "        verbose =-1\n",
    "    )\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    print(np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def bayesOpt(X_train, y_train):\n",
    "    lgbBO = BayesianOptimization(lgb_evaluate, {'numLeaves':  (10, 50),\n",
    "                                                'maxDepth': (2, 63),\n",
    "                                                'scaleWeight': (1, 100),\n",
    "                                                'minChildWeight': (0.01, 70),\n",
    "                                                'subsample': (0.4, 1),                                                \n",
    "                                                'colSam': (0.4, 1)\n",
    "                                            })\n",
    "\n",
    "    lgbBO.maximize(init_points=5, n_iter=5)\n",
    "    print(lgbBO.res['max'])\n",
    "    \n",
    "bayesOpt(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "        colsample_bytree=0.7374, eval_metric='auc',\n",
       "        importance_type='split', learning_rate=0.1, max_depth=12,\n",
       "        metric='auc', min_child_samples=20, min_child_weight=69.29,\n",
       "        min_split_gain=0.0, n_estimators=1000, n_jobs=-1, num_leaves=11,\n",
       "        objective='binary', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, scale_pos_weight=1.476, silent=True,\n",
       "        subsample=0.866, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(class_weight = 'balanced',\n",
    "        objective = 'binary',\n",
    "        metric= 'auc',\n",
    "        eval_metric= 'auc',\n",
    "        n_estimators=1000,\n",
    "        num_leaves= 11,\n",
    "        max_depth= 12,\n",
    "        scale_pos_weight= 1.476,\n",
    "        min_child_weight= 69.29,\n",
    "        subsample= 0.866,\n",
    "        colsample_bytree= 0.7374,\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_sample.drop('target', axis=1)\n",
    "submit_sample['target'] = predicted\n",
    "submit_sample.to_csv('lightgbm_kmeans20.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
